# Day 1: AI Landscape - Resources

## Required Reading

### Before the Session
- [ ] [What is Generative AI?](https://cloud.google.com/ai/generative-ai) - Google Cloud (10 min)

### During Self-Study
- [ ] [Anthropic Claude Documentation](https://docs.anthropic.com) - Capabilities section (20 min)
- [ ] [OpenAI GPT-4 Technical Report](https://openai.com/research/gpt-4) - Summary only (10 min)

---

## Reference Materials

### LLM Fundamentals
| Resource | Type | Time |
|----------|------|------|
| [How Large Language Models Work](https://www.youtube.com/watch?v=zjkBMFhNj_g) | Video | 15 min |
| [Attention Is All You Need](https://arxiv.org/abs/1706.03762) | Paper | Optional |
| [LLM Visualization](https://bbycroft.net/llm) | Interactive | 10 min |

### AI Agents
| Resource | Type | Time |
|----------|------|------|
| [What are AI Agents?](https://www.anthropic.com/research/building-effective-agents) | Article | 15 min |
| [ReAct Pattern Explained](https://arxiv.org/abs/2210.03629) | Paper | Optional |
| [LangChain Agent Concepts](https://python.langchain.com/docs/modules/agents/) | Docs | 20 min |

### Enterprise AI
| Resource | Type | Time |
|----------|------|------|
| [McKinsey: State of AI 2025](https://www.mckinsey.com/capabilities/quantumblack/our-insights/the-state-of-ai) | Report | 30 min |
| [Gartner Hype Cycle for AI](https://www.gartner.com/en/articles/what-s-new-in-artificial-intelligence-from-the-2024-gartner-hype-cycle) | Analysis | 15 min |
| [EU AI Act Summary](https://artificialintelligenceact.eu/) | Regulation | 20 min |

---

## Kyndryl-Specific Resources

*Available on SharePoint: 06-Reference/*

- [ ] KAF (Kyndryl Agentic Framework) Overview
- [ ] AI Innovation Lab Method - 6 Phases
- [ ] Case Study: City of Antibes
- [ ] Case Study: Global Bank AI Assistant

---

## Glossary

| Term | Definition |
|------|------------|
| **LLM** | Large Language Model - AI trained on text to predict next words |
| **GPT** | Generative Pre-trained Transformer - OpenAI's LLM architecture |
| **Token** | A piece of text (roughly 4 characters or 0.75 words) |
| **Prompt** | The input text you give to an LLM |
| **Completion** | The output text generated by an LLM |
| **Context Window** | Maximum text an LLM can process at once |
| **Fine-tuning** | Adapting a pre-trained model on specific data |
| **RAG** | Retrieval-Augmented Generation - connecting LLM to external data |
| **Hallucination** | When AI generates false but confident-sounding information |
| **Agent** | An LLM that can take actions (call APIs, run code, etc.) |
| **Tool Use** | Ability of an agent to call external functions |
| **Chain-of-Thought** | Prompting technique to improve reasoning |
| **System Prompt** | Hidden instructions that shape LLM behavior |
| **Temperature** | Parameter controlling randomness of outputs |
| **Embedding** | Numerical representation of text for similarity search |
| **Vector Database** | Database optimized for storing and searching embeddings |

---

## Tools to Explore

### Try These Today
- [ChatGPT](https://chat.openai.com) - OpenAI's flagship
- [Claude](https://claude.ai) - Anthropic's assistant
- [Gemini](https://gemini.google.com) - Google's model

### For Later Exploration
- [Hugging Face](https://huggingface.co) - Open source models
- [Ollama](https://ollama.ai) - Run models locally
- [LangChain](https://langchain.com) - Agent framework

---

## Recommended Videos

| Title | Duration | When to Watch |
|-------|----------|---------------|
| [Andrej Karpathy: Intro to LLMs](https://www.youtube.com/watch?v=zjkBMFhNj_g) | 1 hour | Self-study |
| [3Blue1Brown: Neural Networks](https://www.youtube.com/watch?v=aircAruvnKk) | 20 min | Optional |
| [Anthropic: Constitutional AI](https://www.youtube.com/watch?v=0LWGpPGKGHc) | 15 min | Self-study |

---

## Questions to Consider

As you explore these resources, think about:

1. What can LLMs do well? What do they struggle with?
2. Why do LLMs hallucinate? Can it be prevented?
3. What makes an "agent" different from a "chatbot"?
4. What are the real risks of enterprise AI adoption?
5. How would you explain this to a non-technical executive?
