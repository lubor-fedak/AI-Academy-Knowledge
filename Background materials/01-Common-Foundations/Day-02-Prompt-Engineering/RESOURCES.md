# Day 2: Prompt Engineering - Resources

## Required Reading

- [ ] [OpenAI Prompt Engineering Guide](https://platform.openai.com/docs/guides/prompt-engineering) (30 min)
- [ ] [Anthropic's Guide to Reducing Hallucinations](https://docs.anthropic.com/claude/docs/reducing-hallucinations) (20 min)

## Reference Materials

### Prompt Engineering
| Resource | Type | Time |
|----------|------|------|
| [Prompting Guide](https://www.promptingguide.ai/) | Guide | 45 min |
| [Chain-of-Thought Prompting](https://arxiv.org/abs/2201.11903) | Paper | Optional |
| [System Prompts Collection](https://github.com/f/awesome-chatgpt-prompts) | Examples | 20 min |

### Hallucination Prevention
| Resource | Type | Time |
|----------|------|------|
| [RAG Overview](https://www.pinecone.io/learn/retrieval-augmented-generation/) | Article | 15 min |
| [Guardrails AI](https://github.com/guardrails-ai/guardrails) | Library | 30 min |
| [LLM Evaluation Techniques](https://www.confident-ai.com/blog/llm-evaluation-metrics-everything-you-need-for-llm-evaluation) | Article | 20 min |

## Glossary

| Term | Definition |
|------|------------|
| **System Prompt** | Hidden instructions that shape AI behavior |
| **User Prompt** | The visible message from the user |
| **Grounding** | Connecting AI to external knowledge sources |
| **RAG** | Retrieval-Augmented Generation |
| **Guardrails** | Rules that constrain AI outputs |
| **Temperature** | Controls randomness (0=deterministic, 1=creative) |
| **Few-shot** | Including examples in the prompt |
| **Zero-shot** | No examples, just instructions |
| **Chain-of-Thought** | Asking AI to show reasoning steps |
| **Jailbreaking** | Tricking AI to bypass safety rules |
